diff -uprN spark-1.1.0-vanilla/bin/compute-classpath.sh spark-1.1.0/bin/compute-classpath.sh
--- spark-1.1.0-vanilla/bin/compute-classpath.sh	2014-09-03 08:00:33.000000000 +0200
+++ spark-1.1.0/bin/compute-classpath.sh	2014-10-16 18:02:18.573515897 +0200
@@ -27,6 +27,8 @@ FWDIR="$(cd `dirname $0`/..; pwd)"
 
 . $FWDIR/bin/load-spark-env.sh
 
+. /etc/default/hadoop
+
 # Build up classpath
 CLASSPATH="$SPARK_CLASSPATH:$SPARK_SUBMIT_CLASSPATH:$FWDIR/conf"
 
@@ -91,6 +93,13 @@ fi
 
 CLASSPATH="$CLASSPATH:$ASSEMBLY_JAR"
 
+# Include Hadoop libraries
+CLASSPATH="$CLASSPATH:$HADOOP_COMMON_HOME/*"
+CLASSPATH="$CLASSPATH:$HADOOP_COMMON_HOME/lib/*"
+CLASSPATH="$CLASSPATH:$HADOOP_HDFS_HOME/*"
+CLASSPATH="$CLASSPATH:$HADOOP_MAPRED_HOME/*"
+CLASSPATH="$CLASSPATH:$HADOOP_YARN_HOME/*"
+
 # When Hive support is needed, Datanucleus jars must be included on the classpath.
 # Datanucleus jars do not work if only included in the uber jar as plugin.xml metadata is lost.
 # Both sbt and maven will populate "lib_managed/jars/" with the datanucleus jars when Spark is
